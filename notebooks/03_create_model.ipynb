{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4535960d-ca4f-45da-843d-44ef139f3218",
   "metadata": {},
   "source": [
    "# 3. Creating your model\n",
    "\n",
    "In the previous notebooks, we learned how to inspect our data and get it ready for neural network training. Here, we'll see how you can customize a neural network so that you can train it with your data.\n",
    "\n",
    "## 3.1 PyTorch modules\n",
    "\n",
    "In PyTorch, all neural networks and neural network layers inherit from [the `torch.nn.Module` base class](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). The most important method of a PyTorch `Module` is [`forward()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward), as it defines how a given input is processed to produce the output. We could, for example, create a `Module` that computes the sum of the sine and cosine of the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c779d84a-28cb-42df-96a1-83bc6d92b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "class Sumsincos(Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x) + torch.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75daa8ca-0ff7-479b-8fa5-ffb6e43d3ae6",
   "metadata": {},
   "source": [
    "To use this `Module`, we first instantiate it and can then call it with an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c4301d-a807-45c2-8d56-2073922479bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0000, -1.0000, -1.0000,  1.0000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumsincos = Sumsincos()\n",
    "\n",
    "x = torch.tensor([0., torch.pi/2, torch.pi, 3*torch.pi/2, 2*torch.pi])\n",
    "\n",
    "sumsincos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe922179-cdf1-4cf0-807f-bf320e563f3d",
   "metadata": {},
   "source": [
    "## 3.2 Choosing a model from the TorchVision library\n",
    "\n",
    "Of course, a `Module` that computes the sum of sines and cosines is of little use if you want to classify Pok√©mon. Convolutional Neural Networks (CNNs) have a better chance. To limit the scope of this lab, we won't be constructing a CNN layer by layer. Instead, we will see how we can slightly modify existing CNN architectures to work for our purpose.\n",
    "\n",
    "The TorchVision library contains plenty of established and state-of-the-art CNN models. Feel free to take a look at [this page](https://pytorch.org/vision/stable/models.html). In this notebook, we'll use [ResNet-18](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18), the tiniest of the popular [ResNet family](https://pytorch.org/vision/stable/models/resnet.html).\n",
    "\n",
    "Initializing a ResNet-18 model is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c30dc02-628c-42a1-8a32-682ccc6e1e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "rn18 = resnet18()\n",
    "rn18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee6937-4a8a-4841-b11f-94dafb1e7dc6",
   "metadata": {},
   "source": [
    "If we initialize the model without any arguments, the model parameters will be initialized with random values. Typically, it is a better idea to use **pretrained parameters**. Let's use the default pretrained weights. For more information on the available weights, see [here](https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66e2c56-bd7b-4000-b93b-76d4fc0e0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn18 = resnet18(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4440d-9eaf-44df-ac03-3380c40a908d",
   "metadata": {},
   "source": [
    "## 3.3 Changing the number of output neurons\n",
    "\n",
    "The ResNet-18 model provided by TorchVision contains 1000 output neurons, as you can see from the `out_features` attribute of the full-connected layer `fc` at the end of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539fbd7d-79f6-43b1-9176-9b48a76dfc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn18.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714954b-dd8d-47d8-a76f-88fc1105d673",
   "metadata": {},
   "source": [
    "Indeed, if we pass a random tensor through this model, we get 10000 predictions for each batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2395fdf-a85a-4dab-97ca-558540a6b9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 5\n",
    "c, h, w = 3, 224, 224\n",
    "\n",
    "x = torch.randn((batch_size, c, h, w))\n",
    "rn18(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17316cb-2309-415c-8691-928b8838f307",
   "metadata": {},
   "source": [
    "This means that the architecture can be used for classifying 1000 classes. Our Pok√©mon dataset contains 149 classes, however. So, we need to replace the current fully-connected layer with one that contains 149 output features (make sure to keep the correct amount of input features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ced63e-e9d2-42a6-8737-27f6c0c3159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "rn18.fc = Linear(in_features=512, out_features=42, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec0a40-a79a-47f6-94eb-9380bcd77bb5",
   "metadata": {},
   "source": [
    "Let's try to pass the random tensor through the new network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ce8ce6-eaa7-49f5-877b-ec29ad7fce1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 42])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn18(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83572475-3506-4c0d-b4f9-c2268cf0b12a",
   "metadata": {},
   "source": [
    "That's it! Our model is now ready for Pok√©mon classification! ü•≥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
